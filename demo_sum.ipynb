{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is to detect objects from the sum filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from Model import Model\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from utils import find_central_point, sum_filter \n",
    "from utils import find_corner, returnHeatmap\n",
    "classes = np.array([\n",
    "        'aeroplane',\n",
    "        'bicycle',\n",
    "        'bird',\n",
    "        'boat',\n",
    "        'bottle',\n",
    "        'bus',\n",
    "        'car',\n",
    "        'cat',\n",
    "        'chair',\n",
    "        'cow',\n",
    "        'diningtable',\n",
    "        'dog',\n",
    "        'horse',\n",
    "        'motorbike',\n",
    "        'person',\n",
    "        'pottedplant',\n",
    "        'sheep',\n",
    "        'sofa',\n",
    "        'train',\n",
    "        'tvmonitor',\n",
    "    ])\n",
    "#location of the input image\n",
    "image_path = './example_images/000071.jpg'\n",
    "annotation_path = './example_images/000071.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rec(filename):\n",
    "    #extract annotation form data\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        obj_struct['pose'] = obj.find('pose').text\n",
    "        obj_struct['truncated'] = int(obj.find('truncated').text)\n",
    "        obj_struct['difficult'] = int(obj.find('difficult').text)\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(bbox.find('xmin').text),\n",
    "                              int(bbox.find('ymin').text),\n",
    "                              int(bbox.find('xmax').text),\n",
    "                              int(bbox.find('ymax').text)]\n",
    "        objects.append(obj_struct)\n",
    "        \n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectdetection(input, threshod=130):\n",
    "    #object detection\n",
    "    net = Model()\n",
    "    net.load_state_dict(torch.load('weights/epoch204densenet.pth'))\n",
    "    net.eval()\n",
    "    \n",
    "    features_blosbs = []\n",
    "    def hook_feature(module, input, output):\n",
    "        #extract feature from the last layer\n",
    "        features_blosbs.append(output.data.cpu().numpy())\n",
    "        \n",
    "    net._modules.get('features').register_forward_hook(hook_feature)\n",
    "    \n",
    "    params = list(net.parameters())\n",
    "    weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "    \n",
    "    #input preprocessing\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    #load image\n",
    "    img_pil = Image.open(input)\n",
    "\n",
    "    img_tensor = preprocess(img_pil)\n",
    "    img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "    logit = net(img_variable)\n",
    "    \n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy()\n",
    "    #generate bounding box\n",
    "    img = cv2.imread(input)\n",
    "    height, width, _ = img.shape  \n",
    "\n",
    "    print('{:.3f} -> {}'.format(probs[0], classes[idx[0]]))\n",
    "    print('index of class', idx[0])\n",
    "    heatmap = returnHeatmap(features_blosbs[0], weight_softmax, [idx[0]])\n",
    "    resized_heat_map = cv2.resize(heatmap[0],(width, height)) \n",
    "    sum_heat_map, maxi_loc = sum_filter(resized_heat_map)\n",
    "    #max_x, max_y is the central point of object, but it is not be used\n",
    "    max_x, max_y = maxi_loc\n",
    "    \n",
    "    #min the left-top corner point, max is the right-bottom point\n",
    "    min, max = find_corner(sum_heat_map, threshod)\n",
    "    min[0], min[1] = min[1], min[0]\n",
    "    max[0], max[1] = max[1], max[0]\n",
    "    print('corner',min, max)\n",
    "\n",
    "    #generate heatmap\n",
    "    heatmap = cv2.applyColorMap(resized_heat_map, cv2.COLORMAP_JET)\n",
    "    heatmap1 = cv2.applyColorMap(sum_heat_map, cv2.COLORMAP_JET)\n",
    "    out_heatmap_ori = heatmap * 0.3 + img * 0.5\n",
    "    out_heatmap_sum = heatmap1 * 0.3 + img * 0.5\n",
    "    #out_heatmap_ori[max_x, max_y, :] = [0,255,0]\n",
    "    cv2.imwrite(os.path.join('tmp', classes[idx[0]]) + '_heatmap_ori.jpg', out_heatmap_ori)\n",
    "    cv2.imwrite(os.path.join('tmp', classes[idx[0]]) + '_heatmap_sum.jpg', out_heatmap_sum)\n",
    "    cv2.imwrite(os.path.join('tmp', classes[idx[0]]) + '_heatmap_only_ori.jpg', resized_heat_map)\n",
    "    cv2.imwrite(os.path.join('tmp', classes[idx[0]]) + '_heatmap_only_sum.jpg', sum_heat_map)\n",
    "    #this code is for find the central code, but don't used\n",
    "    #central_point = cv2.circle(out_heatmap1, (max_x, max_y), 5, (255,0,0))\n",
    "    #cv2.imwrite(os.path.join('tmp', classes[idx[0]]) + '_heatmap_center_point.jpg', central_point)\n",
    "\n",
    "    #generate predict bbox\n",
    "    bbox1 = np.zeros((height, width, 3))\n",
    "    cv2.rectangle(bbox1, (min[0], min[1]), (max[0], max[1]), (255,255,255))\n",
    "    cv2.putText(bbox1, '{:.3f}, {}'.format(probs[0], classes[idx[0]]), (min[0], min[1]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 0)\n",
    "\n",
    "    #generate ground truth bbox\n",
    "    anno = parse_rec(annotation_path)\n",
    "    print('annotation', anno)\n",
    "    bbox2 = np.zeros((height, width, 3))\n",
    "\n",
    "    #save image\n",
    "    for item in anno:\n",
    "        cv2.rectangle(bbox2, (item['bbox'][0], item['bbox'][1]), (item['bbox'][2], item['bbox'][3]), (0, 0, 255))\n",
    "    result = bbox1 + img + bbox2\n",
    "    #cv2.imwrite('CAM.jpg', result)\n",
    "    name = os.path.join('tmp', classes[idx[0]]) + '.jpg'\n",
    "    cv2.imwrite(name, result)\n",
    "\n",
    "    print('end')\n",
    "        \n",
    "    return [max_x, max_y], resized_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763 -> car\n",
      "index of class 6\n",
      "(375, 500)\n",
      "corner [56, 43] [453, 339]\n",
      "annotation [{'name': 'car', 'pose': 'Left', 'truncated': 0, 'difficult': 0, 'bbox': [61, 75, 443, 274]}]\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    central_point, heat_map = objectdetection(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
