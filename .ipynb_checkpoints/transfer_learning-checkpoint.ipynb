{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code is for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import numpy as np\n",
    "import data_preprocessing\n",
    "from Model import Model\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 200\n",
    "class_names = np.array([\n",
    "        'aeroplane',\n",
    "        'bicycle',\n",
    "        'bird',\n",
    "        'boat',\n",
    "        'bottle',\n",
    "        'bus',\n",
    "        'car',\n",
    "        'cat',\n",
    "        'chair',\n",
    "        'cow',\n",
    "        'diningtable',\n",
    "        'dog',\n",
    "        'horse',\n",
    "        'motorbike',\n",
    "        'person',\n",
    "        'pottedplant',\n",
    "        'sheep',\n",
    "        'sofa',\n",
    "        'train',\n",
    "        'tvmonitor',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = 'data/VOCdevkit/VOC2007/ImageSets/Main'\n",
    "image_path = 'data/VOCdevkit/VOC2007/JPEGImages'\n",
    "voc_path = './data/voc'\n",
    "weight_path = 'weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing():\n",
    "    \n",
    "    #data_preprocessing.preprocessing(os.path.join(annotation_path, class_txt), image_path, voc_path)\n",
    "\n",
    "    data_tansforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    trainset = datasets.ImageFolder(voc_path, data_tansforms)\n",
    "    dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    datasize = len(trainset)\n",
    "    class_name = trainset.classes\n",
    "    print(class_name)\n",
    "    \n",
    "    return dataloader, datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epoch=100):\n",
    "    writer = SummaryWriter(comment='Linear')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    model.load_state_dict(torch.load('weights/epoch570.pth'))\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch - 1))\n",
    "        print('-' * 10)\n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        i = 0    \n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            #print('11111', outputs.size(), labels.size())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print(preds, '\\n', labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            i += 1\n",
    "            if i % 10== 0:\n",
    "                print('step: %d loss: %.4f' % (i, loss.item() * inputs.size(0)))\n",
    "        epoch_loss = running_loss / datasize\n",
    "        epoch_acc = running_corrects.double() / datasize\n",
    "        writer.add_scalar('loss', epoch_loss, epoch)\n",
    "        writer.add_scalar('accuracy', epoch_acc, epoch)\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                epoch_loss, epoch_acc))\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, os.path.join(weight_path, 'epoch%d.pth'%epoch))\n",
    "                print('new model saved')\n",
    "                \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=20, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "step: 10 loss: 266.2449\n",
      "step: 20 loss: 279.6216\n",
      "Loss: 1.1074 Acc: 0.6155\n",
      "new model saved\n",
      "Epoch 1/199\n",
      "----------\n",
      "step: 10 loss: 301.0320\n",
      "step: 20 loss: 293.1278\n",
      "Loss: 1.1212 Acc: 0.6087\n",
      "Epoch 2/199\n",
      "----------\n",
      "step: 10 loss: 258.2636\n",
      "step: 20 loss: 295.2849\n",
      "Loss: 1.1152 Acc: 0.6143\n",
      "Epoch 3/199\n",
      "----------\n",
      "step: 10 loss: 279.7082\n",
      "step: 20 loss: 269.3193\n",
      "Loss: 1.1153 Acc: 0.6133\n",
      "Epoch 4/199\n",
      "----------\n",
      "step: 10 loss: 307.9421\n",
      "step: 20 loss: 294.0483\n",
      "Loss: 1.1148 Acc: 0.6065\n",
      "Epoch 5/199\n",
      "----------\n",
      "step: 10 loss: 294.6805\n",
      "step: 20 loss: 298.2646\n",
      "Loss: 1.1305 Acc: 0.6094\n",
      "Epoch 6/199\n",
      "----------\n",
      "step: 10 loss: 273.1690\n",
      "step: 20 loss: 293.1928\n",
      "Loss: 1.1152 Acc: 0.6144\n",
      "Epoch 7/199\n",
      "----------\n",
      "step: 10 loss: 269.2785\n",
      "step: 20 loss: 299.8428\n",
      "Loss: 1.1183 Acc: 0.6142\n",
      "Epoch 8/199\n",
      "----------\n",
      "step: 10 loss: 270.6622\n",
      "step: 20 loss: 279.8676\n",
      "Loss: 1.1215 Acc: 0.6095\n",
      "Epoch 9/199\n",
      "----------\n",
      "step: 10 loss: 281.7628\n",
      "step: 20 loss: 280.6235\n",
      "Loss: 1.1094 Acc: 0.6148\n",
      "Epoch 10/199\n",
      "----------\n",
      "step: 10 loss: 279.3979\n",
      "step: 20 loss: 277.4270\n",
      "Loss: 1.1146 Acc: 0.6080\n",
      "Epoch 11/199\n",
      "----------\n",
      "step: 10 loss: 283.2152\n",
      "step: 20 loss: 277.8601\n",
      "Loss: 1.1166 Acc: 0.6068\n",
      "Epoch 12/199\n",
      "----------\n",
      "step: 10 loss: 301.1614\n",
      "step: 20 loss: 297.0394\n",
      "Loss: 1.1233 Acc: 0.6070\n",
      "Epoch 13/199\n",
      "----------\n",
      "step: 10 loss: 276.5847\n",
      "step: 20 loss: 294.0109\n",
      "Loss: 1.1258 Acc: 0.6100\n",
      "Epoch 14/199\n",
      "----------\n",
      "step: 10 loss: 275.8267\n",
      "step: 20 loss: 297.2448\n",
      "Loss: 1.1093 Acc: 0.6140\n",
      "Epoch 15/199\n",
      "----------\n",
      "step: 10 loss: 305.0999\n",
      "step: 20 loss: 273.0515\n",
      "Loss: 1.1173 Acc: 0.6035\n",
      "Epoch 16/199\n",
      "----------\n",
      "step: 10 loss: 280.1090\n",
      "step: 20 loss: 271.3611\n",
      "Loss: 1.1051 Acc: 0.6146\n",
      "Epoch 17/199\n",
      "----------\n",
      "step: 10 loss: 283.6955\n",
      "step: 20 loss: 288.5665\n",
      "Loss: 1.1052 Acc: 0.6096\n",
      "Epoch 18/199\n",
      "----------\n",
      "step: 10 loss: 284.9415\n",
      "step: 20 loss: 285.8816\n",
      "Loss: 1.1125 Acc: 0.6094\n",
      "Epoch 19/199\n",
      "----------\n",
      "step: 10 loss: 282.5124\n",
      "step: 20 loss: 303.9911\n",
      "Loss: 1.1255 Acc: 0.6076\n",
      "Epoch 20/199\n",
      "----------\n",
      "step: 10 loss: 259.8625\n",
      "step: 20 loss: 251.2631\n",
      "Loss: 1.1168 Acc: 0.6064\n",
      "Epoch 21/199\n",
      "----------\n",
      "step: 10 loss: 293.2176\n",
      "step: 20 loss: 283.7988\n",
      "Loss: 1.1226 Acc: 0.6077\n",
      "Epoch 22/199\n",
      "----------\n",
      "step: 10 loss: 272.7831\n",
      "step: 20 loss: 293.9999\n",
      "Loss: 1.1264 Acc: 0.6068\n",
      "Epoch 23/199\n",
      "----------\n",
      "step: 10 loss: 311.0146\n",
      "step: 20 loss: 281.7926\n",
      "Loss: 1.1206 Acc: 0.6051\n",
      "Epoch 24/199\n",
      "----------\n",
      "step: 10 loss: 272.3346\n",
      "step: 20 loss: 280.3674\n",
      "Loss: 1.1090 Acc: 0.6100\n",
      "Epoch 25/199\n",
      "----------\n",
      "step: 10 loss: 278.3893\n",
      "step: 20 loss: 273.1738\n",
      "Loss: 1.1171 Acc: 0.6111\n",
      "Epoch 26/199\n",
      "----------\n",
      "step: 10 loss: 257.4406\n",
      "step: 20 loss: 269.3617\n",
      "Loss: 1.1152 Acc: 0.6103\n",
      "Epoch 27/199\n",
      "----------\n",
      "step: 10 loss: 311.1963\n",
      "step: 20 loss: 281.2077\n",
      "Loss: 1.1054 Acc: 0.6076\n",
      "Epoch 28/199\n",
      "----------\n",
      "step: 10 loss: 301.9267\n",
      "step: 20 loss: 275.4811\n",
      "Loss: 1.1079 Acc: 0.6095\n",
      "Epoch 29/199\n",
      "----------\n",
      "step: 10 loss: 323.4066\n",
      "step: 20 loss: 302.6812\n",
      "Loss: 1.1178 Acc: 0.6107\n",
      "Epoch 30/199\n",
      "----------\n",
      "step: 10 loss: 277.2376\n",
      "step: 20 loss: 285.6001\n",
      "Loss: 1.1169 Acc: 0.6091\n",
      "Epoch 31/199\n",
      "----------\n",
      "step: 10 loss: 284.3701\n",
      "step: 20 loss: 284.9052\n",
      "Loss: 1.1165 Acc: 0.6117\n",
      "Epoch 32/199\n",
      "----------\n",
      "step: 10 loss: 292.8271\n",
      "step: 20 loss: 271.6502\n",
      "Loss: 1.1067 Acc: 0.6087\n",
      "Epoch 33/199\n",
      "----------\n",
      "step: 10 loss: 286.2746\n",
      "step: 20 loss: 298.8851\n",
      "Loss: 1.1238 Acc: 0.6035\n",
      "Epoch 34/199\n",
      "----------\n",
      "step: 10 loss: 263.6613\n",
      "step: 20 loss: 298.3943\n",
      "Loss: 1.1164 Acc: 0.6100\n",
      "Epoch 35/199\n",
      "----------\n",
      "step: 10 loss: 283.6502\n",
      "step: 20 loss: 272.7917\n",
      "Loss: 1.1106 Acc: 0.6109\n",
      "Epoch 36/199\n",
      "----------\n",
      "step: 10 loss: 257.2752\n",
      "step: 20 loss: 265.8032\n",
      "Loss: 1.1164 Acc: 0.6068\n",
      "Epoch 37/199\n",
      "----------\n",
      "step: 10 loss: 297.8096\n",
      "step: 20 loss: 288.4721\n",
      "Loss: 1.1072 Acc: 0.6114\n",
      "Epoch 38/199\n",
      "----------\n",
      "step: 10 loss: 297.6660\n",
      "step: 20 loss: 276.5804\n",
      "Loss: 1.1057 Acc: 0.6168\n",
      "new model saved\n",
      "Epoch 39/199\n",
      "----------\n",
      "step: 10 loss: 300.3419\n",
      "step: 20 loss: 261.6672\n",
      "Loss: 1.1010 Acc: 0.6142\n",
      "Epoch 40/199\n",
      "----------\n",
      "step: 10 loss: 283.0764\n",
      "step: 20 loss: 270.8061\n",
      "Loss: 1.0929 Acc: 0.6139\n",
      "Epoch 41/199\n",
      "----------\n",
      "step: 10 loss: 273.5980\n",
      "step: 20 loss: 305.0008\n",
      "Loss: 1.1033 Acc: 0.6111\n",
      "Epoch 42/199\n",
      "----------\n",
      "step: 10 loss: 286.6245\n",
      "step: 20 loss: 269.5146\n",
      "Loss: 1.1175 Acc: 0.6095\n",
      "Epoch 43/199\n",
      "----------\n",
      "step: 10 loss: 273.5468\n",
      "step: 20 loss: 286.4011\n",
      "Loss: 1.1098 Acc: 0.6110\n",
      "Epoch 44/199\n",
      "----------\n",
      "step: 10 loss: 290.7512\n",
      "step: 20 loss: 290.8488\n",
      "Loss: 1.1184 Acc: 0.6111\n",
      "Epoch 45/199\n",
      "----------\n",
      "step: 10 loss: 299.4130\n",
      "step: 20 loss: 289.7871\n",
      "Loss: 1.1215 Acc: 0.6031\n",
      "Epoch 46/199\n",
      "----------\n",
      "step: 10 loss: 283.5055\n",
      "step: 20 loss: 294.0872\n",
      "Loss: 1.1199 Acc: 0.6096\n",
      "Epoch 47/199\n",
      "----------\n",
      "step: 10 loss: 307.5474\n",
      "step: 20 loss: 280.7951\n",
      "Loss: 1.1064 Acc: 0.6135\n",
      "Epoch 48/199\n",
      "----------\n",
      "step: 10 loss: 281.0764\n",
      "step: 20 loss: 293.1651\n",
      "Loss: 1.1006 Acc: 0.6168\n",
      "Epoch 49/199\n",
      "----------\n",
      "step: 10 loss: 247.7142\n",
      "step: 20 loss: 295.6737\n",
      "Loss: 1.1075 Acc: 0.6140\n",
      "Epoch 50/199\n",
      "----------\n",
      "step: 10 loss: 287.2820\n",
      "step: 20 loss: 291.7956\n",
      "Loss: 1.1128 Acc: 0.6050\n",
      "Epoch 51/199\n",
      "----------\n",
      "step: 10 loss: 262.9667\n",
      "step: 20 loss: 293.5500\n",
      "Loss: 1.1122 Acc: 0.6038\n",
      "Epoch 52/199\n",
      "----------\n",
      "step: 10 loss: 259.5466\n",
      "step: 20 loss: 331.1685\n",
      "Loss: 1.1139 Acc: 0.6124\n",
      "Epoch 53/199\n",
      "----------\n",
      "step: 10 loss: 264.4868\n",
      "step: 20 loss: 285.9731\n",
      "Loss: 1.1023 Acc: 0.6143\n",
      "Epoch 54/199\n",
      "----------\n",
      "step: 10 loss: 314.2910\n",
      "step: 20 loss: 262.9436\n",
      "Loss: 1.1034 Acc: 0.6079\n",
      "Epoch 55/199\n",
      "----------\n",
      "step: 10 loss: 321.1637\n",
      "step: 20 loss: 246.0365\n",
      "Loss: 1.1009 Acc: 0.6169\n",
      "new model saved\n",
      "Epoch 56/199\n",
      "----------\n",
      "step: 10 loss: 277.7916\n",
      "step: 20 loss: 275.7014\n",
      "Loss: 1.1045 Acc: 0.6176\n",
      "new model saved\n",
      "Epoch 57/199\n",
      "----------\n",
      "step: 10 loss: 297.6887\n",
      "step: 20 loss: 258.8613\n",
      "Loss: 1.1041 Acc: 0.6110\n",
      "Epoch 58/199\n",
      "----------\n",
      "step: 10 loss: 280.7435\n",
      "step: 20 loss: 288.4933\n",
      "Loss: 1.1051 Acc: 0.6146\n",
      "Epoch 59/199\n",
      "----------\n",
      "step: 10 loss: 288.8231\n",
      "step: 20 loss: 278.4328\n",
      "Loss: 1.1204 Acc: 0.6059\n",
      "Epoch 60/199\n",
      "----------\n",
      "step: 10 loss: 293.4567\n",
      "step: 20 loss: 281.4954\n",
      "Loss: 1.1091 Acc: 0.6079\n",
      "Epoch 61/199\n",
      "----------\n",
      "step: 10 loss: 283.1234\n",
      "step: 20 loss: 280.3454\n",
      "Loss: 1.1044 Acc: 0.6096\n",
      "Epoch 62/199\n",
      "----------\n",
      "step: 10 loss: 287.6902\n",
      "step: 20 loss: 262.4321\n",
      "Loss: 1.1187 Acc: 0.6059\n",
      "Epoch 63/199\n",
      "----------\n",
      "step: 10 loss: 286.4985\n",
      "step: 20 loss: 295.3166\n",
      "Loss: 1.1111 Acc: 0.6081\n",
      "Epoch 64/199\n",
      "----------\n",
      "step: 10 loss: 261.6101\n",
      "step: 20 loss: 309.3812\n",
      "Loss: 1.1097 Acc: 0.6131\n",
      "Epoch 65/199\n",
      "----------\n",
      "step: 10 loss: 284.0790\n",
      "step: 20 loss: 274.6100\n",
      "Loss: 1.1045 Acc: 0.6073\n",
      "Epoch 66/199\n",
      "----------\n",
      "step: 10 loss: 302.9146\n",
      "step: 20 loss: 287.3087\n",
      "Loss: 1.1126 Acc: 0.6128\n",
      "Epoch 67/199\n",
      "----------\n",
      "step: 10 loss: 288.5336\n",
      "step: 20 loss: 291.6878\n",
      "Loss: 1.0937 Acc: 0.6150\n",
      "Epoch 68/199\n",
      "----------\n",
      "step: 10 loss: 293.0348\n",
      "step: 20 loss: 318.2497\n",
      "Loss: 1.1142 Acc: 0.6051\n",
      "Epoch 69/199\n",
      "----------\n",
      "step: 10 loss: 279.8250\n",
      "step: 20 loss: 275.9809\n",
      "Loss: 1.1162 Acc: 0.6076\n",
      "Epoch 70/199\n",
      "----------\n",
      "step: 10 loss: 264.2641\n",
      "step: 20 loss: 259.1385\n",
      "Loss: 1.1044 Acc: 0.6131\n",
      "Epoch 71/199\n",
      "----------\n",
      "step: 10 loss: 285.0985\n",
      "step: 20 loss: 280.1427\n",
      "Loss: 1.1160 Acc: 0.6032\n",
      "Epoch 72/199\n",
      "----------\n",
      "step: 10 loss: 282.4148\n",
      "step: 20 loss: 290.4161\n",
      "Loss: 1.1113 Acc: 0.6069\n",
      "Epoch 73/199\n",
      "----------\n",
      "step: 10 loss: 281.3190\n",
      "step: 20 loss: 289.1027\n",
      "Loss: 1.1149 Acc: 0.6203\n",
      "new model saved\n",
      "Epoch 74/199\n",
      "----------\n",
      "step: 10 loss: 302.5543\n",
      "step: 20 loss: 269.6878\n",
      "Loss: 1.1011 Acc: 0.6146\n",
      "Epoch 75/199\n",
      "----------\n",
      "step: 10 loss: 285.0867\n",
      "step: 20 loss: 274.8362\n",
      "Loss: 1.1159 Acc: 0.6073\n",
      "Epoch 76/199\n",
      "----------\n",
      "step: 10 loss: 266.1626\n",
      "step: 20 loss: 284.2690\n",
      "Loss: 1.1106 Acc: 0.6085\n",
      "Epoch 77/199\n",
      "----------\n",
      "step: 10 loss: 304.6561\n",
      "step: 20 loss: 274.0127\n",
      "Loss: 1.1066 Acc: 0.6162\n",
      "Epoch 78/199\n",
      "----------\n",
      "step: 10 loss: 304.6416\n",
      "step: 20 loss: 294.2599\n",
      "Loss: 1.1061 Acc: 0.6122\n",
      "Epoch 79/199\n",
      "----------\n",
      "step: 10 loss: 288.8201\n",
      "step: 20 loss: 272.3939\n",
      "Loss: 1.1054 Acc: 0.6132\n",
      "Epoch 80/199\n",
      "----------\n",
      "step: 10 loss: 311.1745\n",
      "step: 20 loss: 287.7454\n",
      "Loss: 1.1234 Acc: 0.6080\n",
      "Epoch 81/199\n",
      "----------\n",
      "step: 10 loss: 273.1609\n",
      "step: 20 loss: 270.2914\n",
      "Loss: 1.1029 Acc: 0.6091\n",
      "Epoch 82/199\n",
      "----------\n",
      "step: 10 loss: 320.3237\n",
      "step: 20 loss: 285.1004\n",
      "Loss: 1.0943 Acc: 0.6185\n",
      "Epoch 83/199\n",
      "----------\n",
      "step: 10 loss: 274.1784\n",
      "step: 20 loss: 267.0634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1022 Acc: 0.6188\n",
      "Epoch 84/199\n",
      "----------\n",
      "step: 10 loss: 267.2919\n",
      "step: 20 loss: 294.3257\n",
      "Loss: 1.1090 Acc: 0.6102\n",
      "Epoch 85/199\n",
      "----------\n",
      "step: 10 loss: 284.0606\n",
      "step: 20 loss: 267.6597\n",
      "Loss: 1.1103 Acc: 0.6106\n",
      "Epoch 86/199\n",
      "----------\n",
      "step: 10 loss: 291.1405\n",
      "step: 20 loss: 271.9285\n",
      "Loss: 1.1095 Acc: 0.6170\n",
      "Epoch 87/199\n",
      "----------\n",
      "step: 10 loss: 270.3653\n",
      "step: 20 loss: 279.5386\n",
      "Loss: 1.1012 Acc: 0.6116\n",
      "Epoch 88/199\n",
      "----------\n",
      "step: 10 loss: 288.5819\n",
      "step: 20 loss: 246.1158\n",
      "Loss: 1.1158 Acc: 0.6133\n",
      "Epoch 89/199\n",
      "----------\n",
      "step: 10 loss: 273.4310\n",
      "step: 20 loss: 286.4253\n",
      "Loss: 1.1086 Acc: 0.6092\n",
      "Epoch 90/199\n",
      "----------\n",
      "step: 10 loss: 293.4010\n",
      "step: 20 loss: 287.2394\n",
      "Loss: 1.1099 Acc: 0.6085\n",
      "Epoch 91/199\n",
      "----------\n",
      "step: 10 loss: 275.9125\n",
      "step: 20 loss: 297.2411\n",
      "Loss: 1.1048 Acc: 0.6077\n",
      "Epoch 92/199\n",
      "----------\n",
      "step: 10 loss: 282.1859\n",
      "step: 20 loss: 289.4906\n",
      "Loss: 1.1076 Acc: 0.6124\n",
      "Epoch 93/199\n",
      "----------\n",
      "step: 10 loss: 287.5514\n",
      "step: 20 loss: 264.5497\n",
      "Loss: 1.1156 Acc: 0.6080\n",
      "Epoch 94/199\n",
      "----------\n",
      "step: 10 loss: 252.5004\n",
      "step: 20 loss: 279.8333\n",
      "Loss: 1.1053 Acc: 0.6083\n",
      "Epoch 95/199\n",
      "----------\n",
      "step: 10 loss: 311.1890\n",
      "step: 20 loss: 277.9183\n",
      "Loss: 1.1101 Acc: 0.6146\n",
      "Epoch 96/199\n",
      "----------\n",
      "step: 10 loss: 266.8728\n",
      "step: 20 loss: 319.9031\n",
      "Loss: 1.1163 Acc: 0.6058\n",
      "Epoch 97/199\n",
      "----------\n",
      "step: 10 loss: 284.4706\n",
      "step: 20 loss: 270.6492\n",
      "Loss: 1.1020 Acc: 0.6183\n",
      "Epoch 98/199\n",
      "----------\n",
      "step: 10 loss: 276.9110\n",
      "step: 20 loss: 301.6977\n",
      "Loss: 1.1011 Acc: 0.6137\n",
      "Epoch 99/199\n",
      "----------\n",
      "step: 10 loss: 284.1548\n",
      "step: 20 loss: 301.8693\n",
      "Loss: 1.0999 Acc: 0.6113\n",
      "Epoch 100/199\n",
      "----------\n",
      "step: 10 loss: 280.0047\n",
      "step: 20 loss: 297.3781\n",
      "Loss: 1.1115 Acc: 0.6053\n",
      "Epoch 101/199\n",
      "----------\n",
      "step: 10 loss: 261.7359\n",
      "step: 20 loss: 277.1443\n",
      "Loss: 1.0996 Acc: 0.6154\n",
      "Epoch 102/199\n",
      "----------\n",
      "step: 10 loss: 297.1435\n",
      "step: 20 loss: 286.6917\n",
      "Loss: 1.1058 Acc: 0.6117\n",
      "Epoch 103/199\n",
      "----------\n",
      "step: 10 loss: 328.5201\n",
      "step: 20 loss: 278.3692\n",
      "Loss: 1.1049 Acc: 0.6116\n",
      "Epoch 104/199\n",
      "----------\n",
      "step: 10 loss: 280.6683\n",
      "step: 20 loss: 269.5335\n",
      "Loss: 1.1186 Acc: 0.6059\n",
      "Epoch 105/199\n",
      "----------\n",
      "step: 10 loss: 282.6052\n",
      "step: 20 loss: 300.8744\n",
      "Loss: 1.1055 Acc: 0.6092\n",
      "Epoch 106/199\n",
      "----------\n",
      "step: 10 loss: 272.5460\n",
      "step: 20 loss: 273.1626\n",
      "Loss: 1.1066 Acc: 0.6158\n",
      "Epoch 107/199\n",
      "----------\n",
      "step: 10 loss: 281.0484\n",
      "step: 20 loss: 287.6647\n",
      "Loss: 1.0998 Acc: 0.6118\n",
      "Epoch 108/199\n",
      "----------\n",
      "step: 10 loss: 273.8498\n",
      "step: 20 loss: 297.5566\n",
      "Loss: 1.1081 Acc: 0.6072\n",
      "Epoch 109/199\n",
      "----------\n",
      "step: 10 loss: 305.1167\n",
      "step: 20 loss: 273.6929\n",
      "Loss: 1.1088 Acc: 0.6085\n",
      "Epoch 110/199\n",
      "----------\n",
      "step: 10 loss: 278.1861\n",
      "step: 20 loss: 294.1658\n",
      "Loss: 1.1084 Acc: 0.6117\n",
      "Epoch 111/199\n",
      "----------\n",
      "step: 10 loss: 296.6047\n",
      "step: 20 loss: 263.8519\n",
      "Loss: 1.0946 Acc: 0.6144\n",
      "Epoch 112/199\n",
      "----------\n",
      "step: 10 loss: 295.5685\n",
      "step: 20 loss: 284.9807\n",
      "Loss: 1.0968 Acc: 0.6125\n",
      "Epoch 113/199\n",
      "----------\n",
      "step: 10 loss: 295.0329\n",
      "step: 20 loss: 249.1317\n",
      "Loss: 1.1050 Acc: 0.6135\n",
      "Epoch 114/199\n",
      "----------\n",
      "step: 10 loss: 295.8474\n",
      "step: 20 loss: 286.0189\n",
      "Loss: 1.0993 Acc: 0.6142\n",
      "Epoch 115/199\n",
      "----------\n",
      "step: 10 loss: 286.3321\n",
      "step: 20 loss: 287.2834\n",
      "Loss: 1.1188 Acc: 0.6084\n",
      "Epoch 116/199\n",
      "----------\n",
      "step: 10 loss: 265.9233\n",
      "step: 20 loss: 264.7680\n",
      "Loss: 1.1097 Acc: 0.6083\n",
      "Epoch 117/199\n",
      "----------\n",
      "step: 10 loss: 270.0693\n",
      "step: 20 loss: 289.6397\n",
      "Loss: 1.1053 Acc: 0.6174\n",
      "Epoch 118/199\n",
      "----------\n",
      "step: 10 loss: 310.0721\n",
      "step: 20 loss: 251.8163\n",
      "Loss: 1.0909 Acc: 0.6147\n",
      "Epoch 119/199\n",
      "----------\n",
      "step: 10 loss: 283.9121\n",
      "step: 20 loss: 291.9599\n",
      "Loss: 1.1061 Acc: 0.6131\n",
      "Epoch 120/199\n",
      "----------\n",
      "step: 10 loss: 282.8935\n",
      "step: 20 loss: 294.7253\n",
      "Loss: 1.1068 Acc: 0.6139\n",
      "Epoch 121/199\n",
      "----------\n",
      "step: 10 loss: 269.2874\n",
      "step: 20 loss: 277.6717\n",
      "Loss: 1.1052 Acc: 0.6131\n",
      "Epoch 122/199\n",
      "----------\n",
      "step: 10 loss: 276.0523\n",
      "step: 20 loss: 298.4655\n",
      "Loss: 1.0991 Acc: 0.6117\n",
      "Epoch 123/199\n",
      "----------\n",
      "step: 10 loss: 280.9742\n",
      "step: 20 loss: 308.2463\n",
      "Loss: 1.1090 Acc: 0.6139\n",
      "Epoch 124/199\n",
      "----------\n",
      "step: 10 loss: 290.1364\n",
      "step: 20 loss: 293.4977\n",
      "Loss: 1.1111 Acc: 0.6098\n",
      "Epoch 125/199\n",
      "----------\n",
      "step: 10 loss: 287.2317\n",
      "step: 20 loss: 306.1309\n",
      "Loss: 1.1016 Acc: 0.6158\n",
      "Epoch 126/199\n",
      "----------\n",
      "step: 10 loss: 277.3091\n",
      "step: 20 loss: 288.2432\n",
      "Loss: 1.1113 Acc: 0.6083\n",
      "Epoch 127/199\n",
      "----------\n",
      "step: 10 loss: 265.4220\n",
      "step: 20 loss: 290.4478\n",
      "Loss: 1.1050 Acc: 0.6046\n",
      "Epoch 128/199\n",
      "----------\n",
      "step: 10 loss: 260.8174\n",
      "step: 20 loss: 292.8738\n",
      "Loss: 1.0985 Acc: 0.6116\n",
      "Epoch 129/199\n",
      "----------\n",
      "step: 10 loss: 306.4827\n",
      "step: 20 loss: 279.0925\n",
      "Loss: 1.1056 Acc: 0.6079\n",
      "Epoch 130/199\n",
      "----------\n",
      "step: 10 loss: 327.3151\n",
      "step: 20 loss: 276.1039\n",
      "Loss: 1.1161 Acc: 0.6079\n",
      "Epoch 131/199\n",
      "----------\n",
      "step: 10 loss: 278.3346\n",
      "step: 20 loss: 276.4942\n",
      "Loss: 1.1050 Acc: 0.6058\n",
      "Epoch 132/199\n",
      "----------\n",
      "step: 10 loss: 251.8580\n",
      "step: 20 loss: 301.8535\n",
      "Loss: 1.0953 Acc: 0.6209\n",
      "new model saved\n",
      "Epoch 133/199\n",
      "----------\n",
      "step: 10 loss: 280.8470\n",
      "step: 20 loss: 266.9157\n",
      "Loss: 1.1031 Acc: 0.6194\n",
      "Epoch 134/199\n",
      "----------\n",
      "step: 10 loss: 274.4795\n",
      "step: 20 loss: 264.9735\n",
      "Loss: 1.0961 Acc: 0.6163\n",
      "Epoch 135/199\n",
      "----------\n",
      "step: 10 loss: 294.5901\n",
      "step: 20 loss: 256.9614\n",
      "Loss: 1.1117 Acc: 0.6051\n",
      "Epoch 136/199\n",
      "----------\n",
      "step: 10 loss: 284.5996\n",
      "step: 20 loss: 286.2801\n",
      "Loss: 1.0998 Acc: 0.6150\n",
      "Epoch 137/199\n",
      "----------\n",
      "step: 10 loss: 290.1980\n",
      "step: 20 loss: 271.5278\n",
      "Loss: 1.1099 Acc: 0.6054\n",
      "Epoch 138/199\n",
      "----------\n",
      "step: 10 loss: 276.0349\n",
      "step: 20 loss: 261.0345\n",
      "Loss: 1.1024 Acc: 0.6135\n",
      "Epoch 139/199\n",
      "----------\n",
      "step: 10 loss: 284.1942\n",
      "step: 20 loss: 279.8666\n",
      "Loss: 1.1033 Acc: 0.6107\n",
      "Epoch 140/199\n",
      "----------\n",
      "step: 10 loss: 300.1035\n",
      "step: 20 loss: 269.8577\n",
      "Loss: 1.1070 Acc: 0.6122\n",
      "Epoch 141/199\n",
      "----------\n",
      "step: 10 loss: 288.8361\n",
      "step: 20 loss: 268.0904\n",
      "Loss: 1.1018 Acc: 0.6161\n",
      "Epoch 142/199\n",
      "----------\n",
      "step: 10 loss: 297.6304\n",
      "step: 20 loss: 277.0311\n",
      "Loss: 1.0987 Acc: 0.6152\n",
      "Epoch 143/199\n",
      "----------\n",
      "step: 10 loss: 280.3570\n",
      "step: 20 loss: 256.4494\n",
      "Loss: 1.0937 Acc: 0.6154\n",
      "Epoch 144/199\n",
      "----------\n",
      "step: 10 loss: 282.2896\n",
      "step: 20 loss: 279.0520\n",
      "Loss: 1.0932 Acc: 0.6189\n",
      "Epoch 145/199\n",
      "----------\n",
      "step: 10 loss: 258.1828\n",
      "step: 20 loss: 285.0562\n",
      "Loss: 1.1000 Acc: 0.6146\n",
      "Epoch 146/199\n",
      "----------\n",
      "step: 10 loss: 267.2392\n",
      "step: 20 loss: 265.3253\n",
      "Loss: 1.1018 Acc: 0.6114\n",
      "Epoch 147/199\n",
      "----------\n",
      "step: 10 loss: 323.4955\n",
      "step: 20 loss: 274.2026\n",
      "Loss: 1.1074 Acc: 0.6135\n",
      "Epoch 148/199\n",
      "----------\n",
      "step: 10 loss: 289.2141\n",
      "step: 20 loss: 286.6793\n",
      "Loss: 1.1071 Acc: 0.6087\n",
      "Epoch 149/199\n",
      "----------\n",
      "step: 10 loss: 277.9265\n",
      "step: 20 loss: 260.2324\n",
      "Loss: 1.1054 Acc: 0.6151\n",
      "Epoch 150/199\n",
      "----------\n",
      "step: 10 loss: 313.0981\n",
      "step: 20 loss: 272.6966\n",
      "Loss: 1.1064 Acc: 0.6079\n",
      "Epoch 151/199\n",
      "----------\n",
      "step: 10 loss: 243.8708\n",
      "step: 20 loss: 281.2953\n",
      "Loss: 1.0928 Acc: 0.6161\n",
      "Epoch 152/199\n",
      "----------\n",
      "step: 10 loss: 305.2180\n",
      "step: 20 loss: 280.1421\n",
      "Loss: 1.1065 Acc: 0.6129\n",
      "Epoch 153/199\n",
      "----------\n",
      "step: 10 loss: 269.3896\n",
      "step: 20 loss: 273.2890\n",
      "Loss: 1.0916 Acc: 0.6222\n",
      "new model saved\n",
      "Epoch 154/199\n",
      "----------\n",
      "step: 10 loss: 298.1862\n",
      "step: 20 loss: 263.9659\n",
      "Loss: 1.1124 Acc: 0.6116\n",
      "Epoch 155/199\n",
      "----------\n",
      "step: 10 loss: 300.5707\n",
      "step: 20 loss: 295.6850\n",
      "Loss: 1.1223 Acc: 0.6068\n",
      "Epoch 156/199\n",
      "----------\n",
      "step: 10 loss: 297.6487\n",
      "step: 20 loss: 283.2166\n",
      "Loss: 1.1015 Acc: 0.6120\n",
      "Epoch 157/199\n",
      "----------\n",
      "step: 10 loss: 297.2464\n",
      "step: 20 loss: 257.6005\n",
      "Loss: 1.0938 Acc: 0.6074\n",
      "Epoch 158/199\n",
      "----------\n",
      "step: 10 loss: 282.6556\n",
      "step: 20 loss: 321.0951\n",
      "Loss: 1.0901 Acc: 0.6155\n",
      "Epoch 159/199\n",
      "----------\n",
      "step: 10 loss: 273.8499\n",
      "step: 20 loss: 305.7244\n",
      "Loss: 1.0963 Acc: 0.6155\n",
      "Epoch 160/199\n",
      "----------\n",
      "step: 10 loss: 294.9333\n",
      "step: 20 loss: 298.6212\n",
      "Loss: 1.1069 Acc: 0.6098\n",
      "Epoch 161/199\n",
      "----------\n",
      "step: 10 loss: 290.1656\n",
      "step: 20 loss: 285.3016\n",
      "Loss: 1.1017 Acc: 0.6099\n",
      "Epoch 162/199\n",
      "----------\n",
      "step: 10 loss: 273.9473\n",
      "step: 20 loss: 311.5039\n",
      "Loss: 1.0931 Acc: 0.6148\n",
      "Epoch 163/199\n",
      "----------\n",
      "step: 10 loss: 280.4134\n",
      "step: 20 loss: 293.0886\n",
      "Loss: 1.1032 Acc: 0.6143\n",
      "Epoch 164/199\n",
      "----------\n",
      "step: 10 loss: 243.5876\n",
      "step: 20 loss: 267.5296\n",
      "Loss: 1.1096 Acc: 0.6132\n",
      "Epoch 165/199\n",
      "----------\n",
      "step: 10 loss: 254.5526\n",
      "step: 20 loss: 288.3159\n",
      "Loss: 1.0969 Acc: 0.6125\n",
      "Epoch 166/199\n",
      "----------\n",
      "step: 10 loss: 302.0905\n",
      "step: 20 loss: 281.7638\n",
      "Loss: 1.0933 Acc: 0.6185\n",
      "Epoch 167/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10 loss: 274.3252\n",
      "step: 20 loss: 273.2978\n",
      "Loss: 1.0969 Acc: 0.6132\n",
      "Epoch 168/199\n",
      "----------\n",
      "step: 10 loss: 262.2964\n",
      "step: 20 loss: 256.9722\n",
      "Loss: 1.0942 Acc: 0.6177\n",
      "Epoch 169/199\n",
      "----------\n",
      "step: 10 loss: 290.3407\n",
      "step: 20 loss: 292.1843\n",
      "Loss: 1.0905 Acc: 0.6122\n",
      "Epoch 170/199\n",
      "----------\n",
      "step: 10 loss: 305.8938\n",
      "step: 20 loss: 294.9084\n",
      "Loss: 1.0962 Acc: 0.6096\n",
      "Epoch 171/199\n",
      "----------\n",
      "step: 10 loss: 301.4421\n",
      "step: 20 loss: 289.1446\n",
      "Loss: 1.1006 Acc: 0.6131\n",
      "Epoch 172/199\n",
      "----------\n",
      "step: 10 loss: 292.1995\n",
      "step: 20 loss: 298.5277\n",
      "Loss: 1.1023 Acc: 0.6125\n",
      "Epoch 173/199\n",
      "----------\n",
      "step: 10 loss: 256.9338\n",
      "step: 20 loss: 282.4352\n",
      "Loss: 1.1051 Acc: 0.6166\n",
      "Epoch 174/199\n",
      "----------\n",
      "step: 10 loss: 294.8292\n",
      "step: 20 loss: 298.5895\n",
      "Loss: 1.0980 Acc: 0.6120\n",
      "Epoch 175/199\n",
      "----------\n",
      "step: 10 loss: 271.8344\n",
      "step: 20 loss: 256.9460\n",
      "Loss: 1.1156 Acc: 0.6076\n",
      "Epoch 176/199\n",
      "----------\n",
      "step: 10 loss: 309.7329\n",
      "step: 20 loss: 294.4930\n",
      "Loss: 1.1072 Acc: 0.6174\n",
      "Epoch 177/199\n",
      "----------\n",
      "step: 10 loss: 296.6762\n",
      "step: 20 loss: 269.7651\n",
      "Loss: 1.1037 Acc: 0.6103\n",
      "Epoch 178/199\n",
      "----------\n",
      "step: 10 loss: 300.5511\n",
      "step: 20 loss: 288.8617\n",
      "Loss: 1.1057 Acc: 0.6144\n",
      "Epoch 179/199\n",
      "----------\n",
      "step: 10 loss: 296.7134\n",
      "step: 20 loss: 279.9023\n",
      "Loss: 1.1031 Acc: 0.6148\n",
      "Epoch 180/199\n",
      "----------\n",
      "step: 10 loss: 296.8511\n",
      "step: 20 loss: 301.3120\n",
      "Loss: 1.0974 Acc: 0.6099\n",
      "Epoch 181/199\n",
      "----------\n",
      "step: 10 loss: 273.9859\n",
      "step: 20 loss: 305.5757\n",
      "Loss: 1.0989 Acc: 0.6080\n",
      "Epoch 182/199\n",
      "----------\n",
      "step: 10 loss: 289.1406\n",
      "step: 20 loss: 280.1604\n",
      "Loss: 1.1067 Acc: 0.6065\n",
      "Epoch 183/199\n",
      "----------\n",
      "step: 10 loss: 272.0915\n",
      "step: 20 loss: 299.7572\n",
      "Loss: 1.0962 Acc: 0.6166\n",
      "Epoch 184/199\n",
      "----------\n",
      "step: 10 loss: 302.4679\n",
      "step: 20 loss: 262.4273\n",
      "Loss: 1.1021 Acc: 0.6070\n",
      "Epoch 185/199\n",
      "----------\n",
      "step: 10 loss: 293.4230\n",
      "step: 20 loss: 273.2393\n",
      "Loss: 1.0917 Acc: 0.6133\n",
      "Epoch 186/199\n",
      "----------\n",
      "step: 10 loss: 287.2283\n",
      "step: 20 loss: 279.8577\n",
      "Loss: 1.0961 Acc: 0.6113\n",
      "Epoch 187/199\n",
      "----------\n",
      "step: 10 loss: 261.9537\n",
      "step: 20 loss: 268.5309\n",
      "Loss: 1.1021 Acc: 0.6133\n",
      "Epoch 188/199\n",
      "----------\n",
      "step: 10 loss: 283.5625\n",
      "step: 20 loss: 288.4799\n",
      "Loss: 1.0875 Acc: 0.6091\n",
      "Epoch 189/199\n",
      "----------\n",
      "step: 10 loss: 257.7048\n",
      "step: 20 loss: 322.0378\n",
      "Loss: 1.0987 Acc: 0.6059\n",
      "Epoch 190/199\n",
      "----------\n",
      "step: 10 loss: 278.8204\n",
      "step: 20 loss: 286.8810\n",
      "Loss: 1.0970 Acc: 0.6111\n",
      "Epoch 191/199\n",
      "----------\n",
      "step: 10 loss: 292.1573\n",
      "step: 20 loss: 278.3817\n",
      "Loss: 1.0912 Acc: 0.6124\n",
      "Epoch 192/199\n",
      "----------\n",
      "step: 10 loss: 302.4657\n",
      "step: 20 loss: 292.4572\n",
      "Loss: 1.1019 Acc: 0.6120\n",
      "Epoch 193/199\n",
      "----------\n",
      "step: 10 loss: 272.4559\n",
      "step: 20 loss: 286.1501\n",
      "Loss: 1.0972 Acc: 0.6122\n",
      "Epoch 194/199\n",
      "----------\n",
      "step: 10 loss: 252.3041\n",
      "step: 20 loss: 292.5129\n",
      "Loss: 1.0949 Acc: 0.6176\n",
      "Epoch 195/199\n",
      "----------\n",
      "step: 10 loss: 281.0672\n",
      "step: 20 loss: 291.2031\n",
      "Loss: 1.0899 Acc: 0.6152\n",
      "Epoch 196/199\n",
      "----------\n",
      "step: 10 loss: 277.0414\n",
      "step: 20 loss: 251.6879\n",
      "Loss: 1.1047 Acc: 0.6136\n",
      "Epoch 197/199\n",
      "----------\n",
      "step: 10 loss: 287.9707\n",
      "step: 20 loss: 282.5390\n",
      "Loss: 1.1069 Acc: 0.6116\n",
      "Epoch 198/199\n",
      "----------\n",
      "step: 10 loss: 283.0665\n",
      "step: 20 loss: 301.8122\n",
      "Loss: 1.0999 Acc: 0.6087\n",
      "Epoch 199/199\n",
      "----------\n",
      "step: 10 loss: 298.2960\n",
      "step: 20 loss: 285.5668\n",
      "Loss: 1.1096 Acc: 0.6083\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataloader, datasize = data_processing()\n",
    "    \n",
    "    model_ft = Model('densenet')\n",
    "    print(model_ft)\n",
    "\n",
    "    model_ft.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "    model_ft = train_model(model_ft, criterion, optimizer, EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
