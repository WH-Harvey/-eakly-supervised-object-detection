{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to output results for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from Model import Model\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from utils import find_central_point, surf, seedgrowth, accumulate_horiz_and_vert, accumulate_around_pixels\n",
    "from utils import find_corner\n",
    "classes = np.array([\n",
    "        'aeroplane',\n",
    "        'bicycle',\n",
    "        'bird',\n",
    "        'boat',\n",
    "        'bottle',\n",
    "        'bus',\n",
    "        'car',\n",
    "        'cat',\n",
    "        'chair',\n",
    "        'cow',\n",
    "        'diningtable',\n",
    "        'dog',\n",
    "        'horse',\n",
    "        'motorbike',\n",
    "        'person',\n",
    "        'pottedplant',\n",
    "        'sheep',\n",
    "        'sofa',\n",
    "        'train',\n",
    "        'tvmonitor',\n",
    "    ])\n",
    "test_path = './data/VOCdevkit/VOC2007/JPEGImages'\n",
    "det_path = 'eval/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAM(input):\n",
    "    net = Model('densenet')\n",
    "    net.load_state_dict(torch.load('weights/epoch204.pth'))\n",
    "    net.eval()\n",
    "    \n",
    "    features_blosbs = []\n",
    "    def hook_feature(module, input, output):\n",
    "        features_blosbs.append(output.data.cpu().numpy())\n",
    "        \n",
    "    net._modules.get('features').register_forward_hook(hook_feature)\n",
    "    \n",
    "    params = list(net.parameters())\n",
    "    weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "    \n",
    "\n",
    "    def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "        # generate the class activation maps upsample to 256x256\n",
    "        size_upsample = (224, 224)\n",
    "        bz, nc, h, w = feature_conv.shape\n",
    "        output_cam = []\n",
    "        for idx in class_idx:\n",
    "            cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "            cam = cam.reshape(h, w)\n",
    "            cam = cam - np.min(cam)\n",
    "            cam_img = cam / np.max(cam)\n",
    "            cam_img = np.uint8(255 * cam_img)\n",
    "            output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "        return output_cam\n",
    "    \n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    img_pil = Image.open(input)\n",
    "\n",
    "    img_tensor = preprocess(img_pil)\n",
    "    img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "    logit = net(img_variable)\n",
    "    \n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy()\n",
    "    \n",
    "    img = cv2.imread(input)\n",
    "    height, width, _ = img.shape \n",
    "    \n",
    "    for i in range(20):\n",
    "        print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "        CAMs = returnCAM(features_blosbs[0], weight_softmax, [idx[i]])\n",
    "        resized_heat_map = cv2.resize(CAMs[0],(width, height)) \n",
    "        accumulated_heat_map, maxi_loc = accumulate_around_pixels(resized_heat_map)\n",
    "        max_x, max_y = maxi_loc\n",
    "        \n",
    "        min, max = find_corner(accumulated_heat_map, 130)\n",
    "        min[0], min[1] = min[1], min[0]\n",
    "        max[0], max[1] = max[1], max[0]\n",
    "        print(min, max)\n",
    "\n",
    "        \"\"\"bbox1 = np.zeros((height, weight, 3))\n",
    "        print(bbox1.shape)\n",
    "        cv2.rectangle(bbox1, (min[1], min[0]), (max[1], max[0]), (255,255,255))\n",
    "        cv2.putText(bbox1, '{:.3f}, {}'.format(probs[i], classes[idx[i]]), (min[1], min[0]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 0)\n",
    "\n",
    "        result = bbox1 + img\n",
    "        #cv2.imwrite('CAM.jpg', result)\n",
    "        name = os.path.join('tmp', classes[idx[i]]) + '.jpg'\n",
    "        cv2.imwrite(name, result)\n",
    "        print('end')\"\"\"\n",
    "        with open(det_path + '/%s.txt' %classes[idx[i]], 'a') as f:\n",
    "            output = os.path.basename(input) + ' %.4f %d %d %d %d\\n' %(probs[i], min[0], min[1], max[0], max[1])\n",
    "            f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "009535.jpg\n",
      "0.576 -> horse\n",
      "(332, 500)\n",
      "[131, 41] [475, 330]\n",
      "0.396 -> person\n",
      "(332, 500)\n",
      "[114, 50] [444, 331]\n",
      "0.008 -> car\n",
      "(332, 500)\n",
      "[0, 16] [392, 280]\n",
      "0.006 -> cow\n",
      "(332, 500)\n",
      "[17, 57] [399, 331]\n",
      "0.003 -> bicycle\n",
      "(332, 500)\n",
      "[14, 7] [413, 271]\n",
      "0.003 -> pottedplant\n",
      "(332, 500)\n",
      "[3, 17] [403, 307]\n",
      "0.002 -> dog\n",
      "(332, 500)\n",
      "[2, 22] [384, 288]\n",
      "0.001 -> chair\n",
      "(332, 500)\n",
      "[0, 6] [371, 302]\n",
      "0.001 -> bottle\n",
      "(332, 500)\n",
      "[13, 0] [391, 287]\n",
      "0.001 -> boat\n",
      "(332, 500)\n",
      "[0, 8] [392, 284]\n",
      "0.001 -> bird\n",
      "(332, 500)\n",
      "[14, 27] [455, 265]\n",
      "0.001 -> motorbike\n",
      "(332, 500)\n",
      "[16, 0] [430, 261]\n",
      "0.001 -> diningtable\n",
      "(332, 500)\n",
      "[0, 14] [360, 302]\n",
      "0.001 -> train\n",
      "(332, 500)\n",
      "[4, 30] [395, 291]\n",
      "0.000 -> tvmonitor\n",
      "(332, 500)\n",
      "[34, 23] [470, 312]\n",
      "0.000 -> aeroplane\n",
      "(332, 500)\n",
      "[5, 29] [469, 296]\n",
      "0.000 -> bus\n",
      "(332, 500)\n",
      "[5, 15] [377, 284]\n",
      "0.000 -> sheep\n",
      "(332, 500)\n",
      "[3, 24] [382, 292]\n",
      "0.000 -> cat\n",
      "(332, 500)\n",
      "[4, 18] [452, 273]\n",
      "0.000 -> sofa\n",
      "(332, 500)\n",
      "[0, 23] [331, 304]\n",
      "009536.jpg\n",
      "0.697 -> car\n",
      "(375, 500)\n",
      "[69, 44] [479, 374]\n",
      "0.278 -> person\n",
      "(375, 500)\n",
      "[19, 0] [434, 301]\n",
      "0.005 -> pottedplant\n",
      "(375, 500)\n",
      "[84, 16] [493, 329]\n",
      "0.005 -> bicycle\n",
      "(375, 500)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    img_names = os.listdir(test_path)\n",
    "    img_names.sort()\n",
    "\n",
    "    img_names = img_names[4740:]\n",
    "    print('start')\n",
    "    for img_name in img_names:\n",
    "        print(img_name)\n",
    "        CAM(os.path.join(test_path, img_name))\n",
    "    \"\"\"for i in range(0, 1252):#total images are 5011, which divided by 4 is 1252\n",
    "        for j in range(4):\n",
    "            print(j + i*4)\n",
    "            p = Process(target=CAM, args=(os.path.join(test_path, img_names[j + i*4]),))\n",
    "            p.start()\n",
    "    for i in range(3):\n",
    "        q = Process(target=CAM, args=(os.path.join(test_path, img_names[i + 1252*4])))\n",
    "        q.start()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0047,  0.0297,  0.0154,  ..., -0.0187, -0.0266, -0.0019],\n",
      "        [-0.0094,  0.0036,  0.0291,  ...,  0.0255, -0.0018, -0.0149],\n",
      "        [ 0.0219,  0.0112,  0.0019,  ...,  0.0032,  0.0086, -0.0229],\n",
      "        ...,\n",
      "        [-0.0213,  0.0172,  0.0022,  ...,  0.0181,  0.0104,  0.0148],\n",
      "        [-0.0048, -0.0122, -0.0249,  ..., -0.0144, -0.0068,  0.0163],\n",
      "        [-0.0230,  0.0112, -0.0239,  ...,  0.0194, -0.0232, -0.0102]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    img_names = os.listdir(test_path)\n",
    "    img_names.sort()\n",
    "    CAM(os.path.join(test_path, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "a =[1,2,2]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
